/var/spool/slurm/slurmd/job11930780/slurm_script: line 14: activate: No such file or directory
2023-06-17 09:42:02.405173: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2023-06-17 09:42:02.450524: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2023-06-17 09:42:02.451042: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-17 09:42:03.820904: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-17 09:42:06.084072: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
WARNING:tensorflow:From /home/lcur2471/.conda/envs/rs_env/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.
WARNING:tensorflow:From /home/lcur2471/.conda/envs/rs_env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2023-06-17 09:42:07.610009: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled
[]
{'dataset': 'cikm16', 'nepoch': 30, 'batch_size': 512, 'init_lr': 0.003, 'stddev': 0.05, 'emb_stddev': 0.002, 'edim': 100, 'max_grad_norm': 110, 'pad_idx': 0, 'emb_up': True, 'update_lr': False, 'active': 'sigmoid', 'model_save_path': '/output/saved_models/', 'recsys_threshold_acc': 0.68, 'cikm_threshold_acc': 0.62, 'is_print': True, 'cell': 'gru', 'hidden_size': 100, 'cut_off': 20, 'model': 'stamp_cikm', 'class_num': 3}
-------------------------------
reload the datasets.
cikm16
read finish
sort finish
list finish
I am reading
id: 44115
session_id: 600680
items: [10169, 6870, 7100]
click_items: [31062, 10274, 36212]
out: [6870, 7100]
in: [10169, 6870]
label: []

17307
read finish
sort finish
list finish
I am reading
id: 11043
session_id: 600566
items: [2934, 10833]
click_items: [6440, 199109]
out: [10833]
in: [2934]
label: []

17357
dump file done.
-----
Starting training
cikm16
Epoch: 0
Epoch0	loss: 8.534154
Measuring Recall@20 and MRR@20
0.27401837928153716 0.10472167697933384
7.286712
0.27401837928153716 0.1047216769793335
                   max_recall: 0.27401837928153716 max_mrr: 0.1047216769793335
Epoch: 1
Epoch1	loss: 5.976591
Measuring Recall@20 and MRR@20
0.48355263157894735 0.20531818169070884
6.0326805
0.48355263157894735 0.2053181816907113
                   max_recall: 0.48355263157894735 max_mrr: 0.2053181816907113
Epoch: 2
Epoch2	loss: 4.659779
Measuring Recall@20 and MRR@20
0.5493421052631579 0.24444256893514843
5.6841803
0.5493421052631579 0.24444256893514776
                   max_recall: 0.5493421052631579 max_mrr: 0.24444256893514776
Epoch: 3
Epoch3	loss: 4.151803
Measuring Recall@20 and MRR@20
0.5684784878863827 0.24707987212366475
5.570445
0.5684784878863827 0.24707987212366386
                   max_recall: 0.5684784878863827 max_mrr: 0.24707987212366386
Epoch: 4
Epoch4	loss: 3.829973
Measuring Recall@20 and MRR@20
0.5961518379281537 0.28068298054957497
5.4561467
0.5961518379281537 0.2806829805495715
                   max_recall: 0.5961518379281537 max_mrr: 0.2806829805495715
Epoch: 5
Epoch5	loss: 3.543239
Measuring Recall@20 and MRR@20
0.5968045112781954 0.27321122013945437
5.547144
0.5968045112781954 0.27321122013945043
                   max_recall: 0.5968045112781954 max_mrr: 0.27321122013945043
Epoch: 6
Epoch6	loss: 3.381641
Measuring Recall@20 and MRR@20
0.5968306182121972 0.2779811752038132
5.4640613
0.5968306182121972 0.2779811752038086
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 7
Epoch7	loss: 3.279368
Measuring Recall@20 and MRR@20
0.5959429824561403 0.27660604185861887
5.661052
0.5959429824561403 0.276606041858615
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 8
Epoch8	loss: 3.098929
Measuring Recall@20 and MRR@20
0.5957602339181286 0.27402454912263347
5.753661
0.5957602339181286 0.27402454912262897
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 9
Epoch9	loss: 2.959018
Measuring Recall@20 and MRR@20
0.5936455722639933 0.27052497975545015
5.8227525
0.5936455722639933 0.2705249797554469
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 10
Epoch10	loss: 2.847142
Measuring Recall@20 and MRR@20
0.5874060150375939 0.2655487287480947
5.907631
0.5874060150375939 0.2655487287480905
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 11
Epoch11	loss: 2.738998
Measuring Recall@20 and MRR@20
0.5864400584795322 0.2617503400391828
6.023258
0.5864400584795322 0.26175034003918024
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 12
Epoch12	loss: 2.658875
Measuring Recall@20 and MRR@20
0.5822890559732665 0.2567240094709711
6.107166
0.5822890559732665 0.25672400947096913
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 13
Epoch13	loss: 2.556720
Measuring Recall@20 and MRR@20
0.5779814118629908 0.25498737911481295
6.16532
0.5779814118629908 0.25498737911481145
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 14
Epoch14	loss: 2.448767
Measuring Recall@20 and MRR@20
0.5626827485380117 0.2362073277625303
6.422836
0.5626827485380117 0.2362073277625297
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 15
Epoch15	loss: 2.387872
Measuring Recall@20 and MRR@20
0.5612990810359232 0.23869704026616045
6.4715514
0.5612990810359232 0.23869704026615998
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 16
Epoch16	loss: 2.213828
Measuring Recall@20 and MRR@20
0.5654500835421888 0.24249802121572914
6.6334996
0.5654500835421888 0.24249802121572844
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 17
Epoch17	loss: 2.223159
Measuring Recall@20 and MRR@20
0.5605419799498746 0.24769984206728657
6.627802
0.5605419799498746 0.2476998420672852
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 18
Epoch18	loss: 2.153459
Measuring Recall@20 and MRR@20
0.5379072681704261 0.21800580110908535
6.752802
0.5379072681704261 0.2180058011090883
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 19
Epoch19	loss: 2.045200
Measuring Recall@20 and MRR@20
0.533155806182122 0.2200839967692587
6.9260015
0.533155806182122 0.22008399676926102
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 20
Epoch20	loss: 2.038917
Measuring Recall@20 and MRR@20
0.5520833333333334 0.2429580990468897
6.937647
0.5520833333333334 0.24295809904688973
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 21
Epoch21	loss: 1.946301
Measuring Recall@20 and MRR@20
0.5414578111946533 0.22778506894123923
7.088716
0.5414578111946533 0.22778506894124098
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 22
Epoch22	loss: 1.906590
Measuring Recall@20 and MRR@20
0.54156223893066 0.23348753853617488
7.158678
0.54156223893066 0.23348753853617502
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 23
Epoch23	loss: 1.841916
Measuring Recall@20 and MRR@20
0.5382988721804511 0.23147076723127558
7.267142
0.5382988721804511 0.23147076723127558
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 24
Epoch24	loss: 1.793682
Measuring Recall@20 and MRR@20
0.5343306182121972 0.22765101420198033
7.393988
0.5343306182121972 0.22765101420198067
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 25
Epoch25	loss: 1.728060
Measuring Recall@20 and MRR@20
0.5327903091060986 0.2291773243846931
7.470095
0.5327903091060986 0.2291773243846945
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 26
Epoch26	loss: 1.746595
Measuring Recall@20 and MRR@20
0.5232873851294904 0.22315218146113508
7.4968295
0.5232873851294904 0.22315218146113655
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 27
Epoch27	loss: 1.759277
Measuring Recall@20 and MRR@20
0.5231829573934837 0.22294378851930283
7.6095676
0.5231829573934837 0.22294378851930455
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 28
Epoch28	loss: 1.636419
Measuring Recall@20 and MRR@20
0.5242794486215538 0.22569084997051903
7.733781
0.5242794486215538 0.22569084997051986
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
Epoch: 29
Epoch29	loss: 1.627072
Measuring Recall@20 and MRR@20
0.5047514619883041 0.21088250941920456
7.740263
0.5047514619883041 0.2108825094192077
                   max_recall: 0.5968306182121972 max_mrr: 0.2779811752038086
